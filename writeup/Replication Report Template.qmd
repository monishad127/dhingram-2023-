---
title: "` Who is the identifiable victim? Caste and charitable giving in modern India.`"

author: "`Dean Spears, Ashwini Deshpande (dspears@utexas.edu, ashwini.deshpande@ashoka.edu.in)`"
date: "`r format(Sys.time(), '%B %d, %Y')`"
format:
  html:
    toc: true
    toc_depth: 3
---

<!-- Replication reports should all use this template to standardize reporting across projects.  These reports will be public supplementary materials that accompany the summary report(s) of the aggregate results. -->

## Introduction

In their study, Deshpande & Spears (2016) attempt to test how caste and religious identity markers may shape how sympathetic individuals feel towards the out-group. They seek to embed this question within a previously established finding & paradigm pertaining to the identifiable victim effect: whereby researchers have found that people tend to experience more sympathy when victims are defined as specific individuals as against a group identified via broad group-based categorical labels such as “Hindus, Dalits, Whites or Blacks”(Henceforth referred to as a statistical group). Deshpande & Spears (2016) find that indeed participants are more generous to victims who are identified via generic Indian, upper caste name, and Muslim background as against their statistical counterparts. However, they find no evidence for the impact of the identifiability of victims on donations made to Dalits. Whereby Dalit recipients receive equally few donations when they are identified as individual victims or statistical groups. Researchers also find no significant discrimination between donations made to Dalits, Muslims, and upper caste groups when identified as ‘social or statistical groups’. Participants in the study were from largely upper-caste, internet-savvy, literate, high SES backgrounds.
 

##Motivation to replicate:

The results obtained by Deshpande & Spears (2016) differ from one of my experiments where I tested the impact of exposure to nationalistic ideas on donations made to upper-caste, Dalit and Hindu recipients. In the control group of my study (n =90)  I found no significant discrimination between donations to Dalits (n =30) and Upper-caste recipients (n =30) (identified via their caste names). However, I find marginally significant discrimination towards Muslims (n = 30, p = 0.108). Upon exposure to nationalistic norms, I found that donations made to Muslims were reduced significantly as compared to donations made to upper-caste hindus & Dalits. However, donations made to Dalits remain unaffected in response to exposure to nationalistic norms, any changes are statistically insignificant in comparison to the upper caste. I have recently conducted another study to test whether these effects replicate. Replicating Deshpande & Spears (2016) gives me an additional opportunity to re-test the relative authenticity of the results obtained in the control group of my experiment. And allows me to further build on these results to aid a third replication of my nationalism experiment. 

##The present study: 

Since finding discrimination against Dalits, but non against Muslims (in the identifiability condition) is the most striking finding reported by Deshpande & Spears, my study will focus on replicating this finding. 

##Challenges:  

Bots & Turk farms: Mturk samples in India are known to be fraught with bots, and Turk farms, which have been increasingly reported to skew the quality of data collection. Based on anecdotes from researchers, I have learnt that such problems have increased over the years, and therefore I am more likely to experience such concerns than the authors of the study did in 2015.  I am therefore sceptical of using a Mturk sample to replicate the study. There are other agencies that offer online panel services in India, alongside data quality assurances. Given that my replication isn’t geared towards mapping data quality concerns on Mturk, I believe I should ideally access other services that will provide a better, more robust replication test of the experiment design. 

Regional skew: Anecdotal evidence, based on the experience of other researchers, points towards an increasing regional skew within the Mturk working population. Whereby participants are known to be located in Southern parts of India. Deshpande & Spears (2016) however utilize north Indian caste names to indicate caste. A South Indian participant will not be able to accurately categorize and infer the appropriate caste via the names signalled in the prime. Given that Mturk doesn’t allow us to sample the population via region If I use Mturk I am likely to recruit a larger South India population, this will in turn affect the replicability of the experiment. 


Power: Deshpande & Spears (2016) recruited a sample of 400 participants, incidently their sample was a homogeneous group of upper-caste hindus. This led the researchers to obtain 50 upper caste Hindu participants per treatment group. Such homogeneous recruitment of upper case hindus is however not always possible. It is likely that in our recruitment we will not be able to pre-emptively control for demographics. If we ask participants to report their caste at the start of the survey and exclude them on the basis of caste, this will amount to discrimination, and also inadvertently prime caste/ religious identity. Therefore accounting for potential heterogeneity in the recruited sample, and the statistical procedures needed to control for the same, we would need to increase our sample to 800 to have an 80 % chance of seeing the effect size at 0.05 significance level. I assume that we will have at least 100-150 people from OBC, SC, and Muslim backgrounds in our sample (each). However, if we work with an agency we can work with  a pre-defined panel of upper caste groups as our sample. 

https://github.com/monishad127/dhingram-2023-.git


## Methods


### Power Analysis

The original effect size isnt reported, however based on the power calculation and keeping mind limitations noted above I note the following estimate re-power: I would need a sample of 400 to detect a small effect (0.2) at 80 % power, and 0.05 level of significance. 

### Planned Sample

I will be recruiting the sample from Mturk

### Materials

Participants will be randomly assigned to read about an identified recipient from a Dalit, Muslim or upper caste Hindu background.The identification of the recipient’s category will be made only implicitly by their name, using well-known male names commonly associated with Dalit, Muslim, Upper Caste Hindu categories. Deshpande & Spears (2015) utilized 20 names, five for each group; each participant was assigned to read about an identifiable recipient and read only one of these five names, randomly presented. For the control treatment, researchers used names that are commonly found across caste levels and are not identified with a particular group. However, since the authors have established (through study 3) that each of these names signals a caste & religious category, I will utilize names with the highest signalling value (factor loading) as indicated in study 3 of the paper. 

The following materials will be utilized to indicate ‘individual’ characteristics of the recipients. 


Those assigned to an identifiable victim treatment read: The family of NAME is very poor. For much of each year, they cannot find work. His family frequently cannot afford enough basic food to eat. As a result, his children go without medicine if they get sick, and often go to bed hungry. 


The following attention checks and instructional manipulations will be administered:

“How often have you suffered a fatal heart attack?” Only those who selected “never” were included in the analyzed sample. 

“On many important issues, people have different opinions. Some people
agree, and some people disagree, even very strongly. Here in this question,
please select the number four in the slider below, to rule out random clicking.”

The following manipulation check will be used: 

Please identify which of the following social categories does the "recepient name" belong to? 

To understand how participants self-categorize themselves into a social group, participants will be requested to answer the following questions: 

How much do you believe your family is like a typical family of each of the following types?” The 10 groups, as they will be written on the survey form are as follows: Brahmin, Forward/Upper Castes, OBC ½Other Backward Classes, Dalits, Dalit/SC, Adivasi/ST, Scheduled Tribe; marginalized tribal communities, Muslim, Poor, Middle class, Rural, and Urban.


### Procedure	

Experiment Design

Deshpande & Spears (2016) recruited an Indian Sample via Mturk to conduct an online survey experiment to test the interaction of caste and religious identity with the identifiable victim effect. First, participants are shown the experimental prompt: a few sentences of text describing an opportunity for charitable giving. The identity of the recipient receiving the charity is randomised. Participants either see recipients from Muslim, Dalit, upper-caste Hindu or general Indian backgrounds.  The experiment is thus set up as 4(social identity) x 1 (identifiable victim) between group factorial design. Immediately after exposure to the stimuli, participants are asked to rate their willingness to donate. To measure this key dependent variable,  participants are shown a scale ranging from Rs. 0 to 100 and are asked how much money they would be willing to donate. Following this, participants are asked a set of attention check & manipulation check questions. Finally, participants rated the similarity of their family to typical members of 10 different social groups cutting across class, caste, religious and neighbourhood characteristics. Followed by a demographic questionnaire.

Link to the questionnaire:
https://lse.eu.qualtrics.com/jfe/form/SV_3lRdcGRosB4KV5c

### Analysis Plan


Following Deshpande & Spears (2016), I will replicate the 
main effect of social identity of the recipient on donations. Utilizing linear regressionI will test the impact of social identity  on donations. 

**Clarify key analysis of interest here**  
Expecting socio-economic diversity in my sample,I will add controls for income in the main regression analysis. 

### Differences from Original Study

1. I am only replicating the impact of social identity on donations. And not the interaction between identifiability and social identity.

2.I am utilizing caste & religous names with the highest factor loading, instead of randomly assigning 5 different names to indicate caste/ religion.






### Methods Addendum (Post Data Collection)

LINK to the paradigm:

https://lse.eu.qualtrics.com/jfe/form/SV_do54v6hPmmOmhTg

I collected data via Mturk platform. Despite the procedural issues, the data collection was smooth & quick. Unfortunately, the effeciacy of data collection doesn't match up to the quality. I note below the actual sample I am able to utlize in my study.

#### Actual Sample
  I collected a sample of 324 participants.81 Participants were from general category/ Upper caste backrgound; 3 were from EWS backgriund, 48 were OBCcreamy layer, 23 were OBC non creamy layer, 22 were from Scheduled Caste background, and 7 were from scheduled tribe backrgound. I 29excluded participants from SC & ST backrgound. I excluded 32 participants from Muslim & Christian Background (this overlapped with caste), and I removed 120 participants who failed the attention check.After removing participants who did not meet the Manipulation check, I was left with a final sample of 88 participants.
  
  
  
  
#### Differences from pre-data collection methods plan
  Any differences from what was described as the original plan, or “none”.


## Results


### Data preparation

Data preparation following the analysis plan.
	
```{r include=F}
### Data Preparation

#### Load Relevant Libraries and Functions




library("tidyverse")

library(readxl)

library("stargazer")





#### Import data

RepData <- read_excel("C:\\Users\\HP\\Downloads\\RepData2x.xls")


View(RepData)

summarize(RepData)

colnames(RepData)

#### Data exclusion / filtering

## filtering data as per the relevant Attention Checks.

Filtered_RepData <- RepData %>%
                    filter(AC_1 == 4, AC_2 == 4)

D <- Filtered_RepData


## filtering data as per relevant Manipulation checks 


#### Prepare data for analysis - create columns etc.
```
##reading data into R

```{r}

##descriptive statistics: 

summary(D)



```

```{r}
##subsetting the data

##Checking the caste categroy of the participants.

table(D$Caste_category)

caste_freq <- table(D$Caste_category)

caste_freq

# Custom names for each bar/category
bar_names <- c("General", "EWS", " OBC-C","OBC", "SC", "ST")  


bp <- barplot(caste_freq,
              names.arg = bar_names,  # Using custom names
              xlab = "Caste category", 
              ylab = "Frequency",
              main = "Caste distribution in the sample",
              col = "yellow")

##most participants belong to General caste, followed by OBC-C
##The key question was to understand whether upper caste hindus are discriminatory towards Dalits & Muslims -- however the data collected has participants from different caste groups, Deshpande & Spears only had upper caste participants in their sample. Therefore I will work with two data sets: dataset 1 will have only upper caste & OBC creamy layer participants, datset 2 will have participants from heterogenous caste groups. I will control for caste while analysing dataset 2. 

##checking for religion: 

table(D$Religion)

Religion_freq <- table(D$Religion)

# Custom names for each bar/category
bar_names2 <- c("Hindu", "Muslim", "Christian")  

bp2 <- barplot(Religion_freq,
              names.arg = bar_names2,  # Using custom names
              xlab = "Religion", 
              ylab = "Frequency",
              main = "reliogious distribution in the sample",
              col = "orange")
```


```{r}

##removing participants from Muslim,Christian, Scheduled Caste, Scheduled tribe backgrounds:

## subsetting the data via Manipulation checks

DM <- D %>%
  filter(Religion == 1 & Caste_category %in% c(1, 3, 4, 5) &
         (MCMM == 1 | MCIM == 1 | MCIG == 1 | MCDD == 1 | MCID == 1 | MCHD == 1 | 
          MC_B == 4 | MC_B == 2 | MC_B == 5 | MC_B == 6))



```




```{r}
 ##Selecting relevant variables


DD1 <- select(DM, -contains("Objects"), -contains("HS"), -RandomID)

```

`
```



```
  


##pivoting the data

```{r}

FDlongx <- DD1 %>%
  pivot_longer(
    cols = c("MI", "GI", "DI", "BI"),
    names_to = 'treatment',
    values_to = 'donations',
    values_drop_na = TRUE
  )


## converting the key variables into dummies


dummy_dat9 <- FDlongx %>% mutate(treatment = factor(treatment)) %>% pivot_wider(names_from = treatment, values_from = treatment, values_fn = length, values_fill = 0)

dummy_dat9
```


```{r}

##plotting donations across treatment conditions

library(ggplot2)


FDlongx$treatment <- factor(FDlongx$treatment,
                            levels = c("BI", "GI", "MI", "DI"),
                            labels = c("Brahmin", "Generic-Indian", "Muslim", "Dalit")) 




ggplot(data = FDlongx, aes(x = treatment, y = donations)) +
  geom_bar(stat = "identity", fill = "blue") +
  scale_y_continuous(limits = c(0, 100)) +
  labs(title = "Donations Across Recipients",
       x = "Recipients", y = "Donations")


```

```{r}


##main result:
##Linear regression for the main effect:
  

model1 <- lm(donations ~ MI + GI + DI + BI + Caste_category,
               data = dummy_dat9)

summary(model1)



stargazer(model1, type = "text",
          covariate.labels = c("Muslim for MI", "Brahmin for BI", "Generic Indian for GI", "Dalit for DI"),
          title = "Results of Model1")


                              


```
##Results:
The sample is too small for me to seek any evidence of replication from the linear model presented above.

## Discussion & summary:
Unfortunately, the results of the present study cannot speak to the results obtained by Deshpande & Spears (2016). The limitations and the quality of the data collected prevents me from taking any stance on whether or not the results of the original study replicate. I am now going to sequentially note down each of these limitations. Though these limitations emerge in referece to Deshpande & Spears (2016) sample, I
hope that these limitations will help further attempts to collect experimental data via Mturk from Indian participants. 

1. First, the sample of participants who took the survey from a heterogeneous Caste & Religius backgrounds. I have noted this heterogeniety above. Since this was an experimental study, asking participants to report their caste & religion at the start as a filter would have introduced a prime that can confound main results.Given that only about 130 participants belong to UC background, I relaxed the caste criteria of inclusion by adding participants from the OBC background to my data. I later controlled for caste.

2. Participants were from different regions across India. This stands consonent with Deshpande & Spears, who didn't have a location based filter based  on region. However Deshpande & Spears used north Indian caste names, and these names can likely be unfamiliar to sample from South India. Keeping this limitation in mind,in order to increase the chances of replication I had tried to restrict the sample to North India, however this affected the timeline of data collection, as there were fewer north Indian participants. Consequently, I relaxed this criteria. I consequently was strict with removing participants who didn't meet the manipulation check. This reduced the sample size, and the affected my ability to come up with any conclusive inference vis-a-vis replication of these results. 

3. Lastly, a large number of participants failed the attention check questions. I had field a very short survey, and the Attention check questions were very straight forward. However, despite this I was forced to remove more than 100 participants, nearly 40 % of the entire sample collected. This is indicative of the general engagement of the Mturk workers, and the consecuent data quality of Mturk studies fielded in India. 

Overall, I'd like to thank Mike, Sarah, Veronica and Ben for allowing me to replicate this study, funding the data collection, and supporting me through the mores of replication, Rstudio, and in engaging with Mturk. I think
the study was revealing, re the potential feasibility of using Mturk to collect experimental, & geographically sensitive political data.


https://github.com/psych251/dhingram-2023-/blob/main/writeup/Replication%20Report%20Template.qmd

https://github.com/psych251/dhingram-2023-














